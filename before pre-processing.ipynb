{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kode di atas mengimpor library Python yang digunakan untuk pemrosesan citra, analisis data, dan machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertGambar(folder):\n",
    "    data = []\n",
    "    filenames = []\n",
    "    datalabel = [] \n",
    "    path = []\n",
    "    data_distribution = {}\n",
    "    for label in (os.listdir(folder)):\n",
    "        images = os.listdir(folder+label)\n",
    "        data_distribution[label] = len(images)\n",
    "        datalabel.append(label)\n",
    "        print(label)\n",
    "        count = 0\n",
    "        for filename in tqdm(os.listdir(folder+label)):\n",
    "            if count == 100:\n",
    "                break\n",
    "            else :\n",
    "                count += 1\n",
    "            img = cv.imread(os.path.join(folder+label,filename))\n",
    "            if img is not None:\n",
    "                img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "                filenames.append(filename)\n",
    "                path.append(label)\n",
    "                data.append(img)\n",
    "    return data, filenames, datalabel, path , data_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi insertGambar membaca gambar dari folder yang berisi subfolder dengan label berbeda. Gambar-gambar tersebut dikonversi ke format RGB dan disimpan dalam daftar bersama dengan nama file dan labelnya. Fungsi ini juga membatasi jumlah gambar yang diambil per label hingga 100 dan menghitung distribusi data untuk setiap label. Hasilnya adalah kumpulan data gambar, nama file, label, jalur label, dan distribusi data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 373.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plastic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 439.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 414.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:  300\n",
      "Label:  3\n",
      "Filenames:  300\n",
      "Data Distribution:  {'paper': 100, 'plastic': 100, 'trash': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data, filenames,label, path, distribusi = insertGambar(\"dataset/\") \n",
    "print(\"Data: \", len(data))\n",
    "print(\"Label: \", len(label))\n",
    "print(\"Filenames: \", len(filenames))\n",
    "print(\"Data Distribution: \", distribusi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi insertGambar membaca gambar dari folder \"dataset/\", mengembalikan data gambar, nama file, label, jalur label, dan distribusi data. Kode ini kemudian mencetak jumlah gambar, jumlah label, jumlah nama file, dan distribusi data per label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayScaling(img):\n",
    "    gaussKernel = np.ones((3,3))/9\n",
    "    r = img[:,:,2]\n",
    "    g = img[:,:,1]\n",
    "    b = img[:,:,0]\n",
    "    filteredR = cv.filter2D(r,-1,gaussKernel)\n",
    "    filteredG = cv.filter2D(g,-1,gaussKernel)\n",
    "    filteredB = cv.filter2D(b,-1,gaussKernel)\n",
    "    return np.round(filteredR/3 + filteredG/3 + filteredB/3).astype(np.uint8)\n",
    "\n",
    "def grayScalingData(data):\n",
    "    gray_data = []\n",
    "    for i in tqdm(range(len(data))):\n",
    "        gray_data.append(grayScaling(data[i]))\n",
    "    return gray_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi grayScaling mengonversi gambar berwarna menjadi grayscale dengan mengaplikasikan filter Gaussian pada setiap kanal warna dan menggabungkannya. Fungsi grayScalingData menerapkan grayScaling pada setiap gambar dalam data dan menyimpan hasilnya dalam gray_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:03<00:00, 78.22it/s] \n"
     ]
    }
   ],
   "source": [
    "grayData = grayScalingData(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kode di atas adalah penerapan convert ke grayscale data yang diikuti dengan menampilkan sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matriksTransformasi(matriks):\n",
    "    hasil = np.zeros(matriks.shape)\n",
    "    for i in range(matriks.shape[0]):\n",
    "        for j in range(matriks.shape[1]):\n",
    "            hasil[i][j] = matriks[j][i]\n",
    "    return hasil\n",
    "def sum(matriks):\n",
    "    hasil = 0\n",
    "    for i in range(len(matriks)):\n",
    "        for j in range(len(matriks[0])):\n",
    "            hasil += matriks[i][j]\n",
    "    return hasil\n",
    "\n",
    "def derajat(img, derajat):\n",
    "    max = np.max(img)\n",
    "    temp=np.zeros([max+1,max+1])\n",
    "    if derajat == 0:\n",
    "        for i in range (len(img)):\n",
    "            for j in range (len(img[0])-1):\n",
    "                temp[img[i,j],img[i,j+1]] += 1\n",
    "    elif derajat == 45:\n",
    "        for i in range (len (img)-1):\n",
    "            for j in range (len (img[0])-1):\n",
    "                temp[img[i+1,j],img[i,j+1]] += 1\n",
    "    elif derajat == 90:\n",
    "        for i in range (len (img)-1):\n",
    "            for j in range (len (img[0])):\n",
    "                temp[img[i+1,j],img[i,j]] += 1\n",
    "    elif derajat == 135:\n",
    "        for i in range (len (img)-1):\n",
    "            for j in range (len (img[0])-1):\n",
    "                temp[img[i,j],img[i+1,j+1]] += 1\n",
    "    hasil = temp+matriksTransformasi(temp)\n",
    "    total = sum(hasil)\n",
    "    for i in range (len (hasil)):\n",
    "        for j in range (len (hasil)):\n",
    "            hasil[i,j]/=total\n",
    "    return hasil\n",
    "\n",
    "def ekstraksi(image):\n",
    "    hasil = []\n",
    "    for img in tqdm(image):\n",
    "        data = []\n",
    "        data.append(derajat(img,0))\n",
    "        data.append(derajat(img,45))\n",
    "        data.append(derajat(img,90))\n",
    "        data.append(derajat(img,135))\n",
    "        hasil.append(data)    \n",
    "    return hasil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi derajat menghitung matriks co-occurrence untuk gambar pada sudut tertentu dan menormalkannya. Fungsi ekstraksi menerapkan derajat pada setiap gambar dalam image untuk berbagai sudut dan menyimpan hasilnya dalam hasil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [03:59<00:00,  1.25it/s]\n"
     ]
    }
   ],
   "source": [
    "ekstraksiData = ekstraksi(grayData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kode di atas adalah penerapan fungsi ekstraksi pada data gray yang digunakan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast (data):\n",
    "    hasil = 0\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[0])):\n",
    "            hasil+=data[i,j]*pow(i-j,2)\n",
    "    return hasil\n",
    "def dissimilarity(data):  \n",
    "    hasil = 0\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[0])):\n",
    "            hasil+=data[i,j]*abs(i-j)\n",
    "    return hasil\n",
    "def homogeneity(data):\n",
    "    hasil = 0\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[0])):\n",
    "            hasil+=(data[i,j]/(1+pow(i-j,2)))\n",
    "    return hasil\n",
    "def energy(data):\n",
    "    hasil = 0\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[0])):\n",
    "            hasil += data[i][j] ** 2\n",
    "    return hasil\n",
    "\n",
    "def correlation(data):\n",
    "    mean_x = 0\n",
    "    mean_y = 0\n",
    "    std_x = 0\n",
    "    std_y = 0\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[0])):\n",
    "            mean_x += i * data[i][j]\n",
    "            mean_y += j * data[i][j]\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[0])):\n",
    "            std_x += (i - mean_x) ** 2 * data[i][j]\n",
    "            std_y += (j - mean_y) ** 2 * data[i][j]\n",
    "    std_x = math.sqrt(std_x)\n",
    "    std_y = math.sqrt(std_y)\n",
    "    hasil = 0\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[0])):\n",
    "            hasil += (i - mean_x) * (j - mean_y) * data[i][j]\n",
    "    hasil /= std_x * std_y\n",
    "    return hasil\n",
    "\n",
    "def entropy(data):\n",
    "    entropy = 0\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[0])):\n",
    "            if data[i][j] > 0.0:\n",
    "                entropy += -(data[i][j] * math.log(data[i][j]))\n",
    "    return entropy\n",
    "def asm(data):\n",
    "    asm = 0\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[0])):\n",
    "            asm += data[i][j] ** 2\n",
    "    return asm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ekstraksiFitur(data, path):\n",
    "    hasil = []\n",
    "    batas_gambar = len(data)\n",
    "    for i in tqdm(range(batas_gambar)):\n",
    "        extracted_data = [path[i]]\n",
    "        for j in range(len(data[i])):\n",
    "            contrast_val = contrast(data[i][j])\n",
    "            extracted_data.append(contrast_val)\n",
    "        for j in range(len(data[i])):\n",
    "            dissimilarity_val = dissimilarity(data[i][j])\n",
    "            extracted_data.append(dissimilarity_val)\n",
    "        for j in range(len(data[i])):\n",
    "            homogeneity_val = homogeneity(data[i][j])\n",
    "            extracted_data.append(homogeneity_val)\n",
    "        for j in range(len(data[i])):\n",
    "            energy_val = energy(data[i][j])\n",
    "            extracted_data.append(energy_val)\n",
    "        for j in range(len(data[i])):\n",
    "            correlation_val = correlation(data[i][j])\n",
    "            extracted_data.append(correlation_val)\n",
    "        for j in range(len(data[i])):\n",
    "            asm_val = asm(data[i][j])\n",
    "            extracted_data.append(asm_val)\n",
    "            entropy_val = entropy(data[i][j])\n",
    "            extracted_data.append(entropy_val)\n",
    "        hasil.append(extracted_data)\n",
    "    return hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = ['0', '45', '90', '135']\n",
    "fiturs = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']\n",
    "headers = ['path']\n",
    "for fitur in fiturs:\n",
    "    headers.extend([f'{fitur}_{angle}' for angle in angles])\n",
    "headers.extend([f'asm_{angle}' for angle in angles])\n",
    "headers.extend([f'entropy_{angle}' for angle in angles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:12<00:00,  1.04s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>contrast_0</th>\n",
       "      <th>contrast_45</th>\n",
       "      <th>contrast_90</th>\n",
       "      <th>contrast_135</th>\n",
       "      <th>dissimilarity_0</th>\n",
       "      <th>dissimilarity_45</th>\n",
       "      <th>dissimilarity_90</th>\n",
       "      <th>dissimilarity_135</th>\n",
       "      <th>homogeneity_0</th>\n",
       "      <th>...</th>\n",
       "      <th>correlation_90</th>\n",
       "      <th>correlation_135</th>\n",
       "      <th>asm_0</th>\n",
       "      <th>asm_45</th>\n",
       "      <th>asm_90</th>\n",
       "      <th>asm_135</th>\n",
       "      <th>entropy_0</th>\n",
       "      <th>entropy_45</th>\n",
       "      <th>entropy_90</th>\n",
       "      <th>entropy_135</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paper</td>\n",
       "      <td>34.627981</td>\n",
       "      <td>65.114734</td>\n",
       "      <td>31.449973</td>\n",
       "      <td>62.041637</td>\n",
       "      <td>1.953303</td>\n",
       "      <td>2.805322</td>\n",
       "      <td>1.718842</td>\n",
       "      <td>2.611155</td>\n",
       "      <td>0.713239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993843</td>\n",
       "      <td>0.987868</td>\n",
       "      <td>0.010774</td>\n",
       "      <td>6.293078</td>\n",
       "      <td>0.009106</td>\n",
       "      <td>6.579898</td>\n",
       "      <td>0.010514</td>\n",
       "      <td>6.261537</td>\n",
       "      <td>0.009089</td>\n",
       "      <td>6.544980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paper</td>\n",
       "      <td>22.833313</td>\n",
       "      <td>24.654034</td>\n",
       "      <td>3.293407</td>\n",
       "      <td>26.701011</td>\n",
       "      <td>2.510284</td>\n",
       "      <td>2.726927</td>\n",
       "      <td>1.191559</td>\n",
       "      <td>2.855370</td>\n",
       "      <td>0.449226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999565</td>\n",
       "      <td>0.996460</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>7.319258</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>7.409926</td>\n",
       "      <td>0.005112</td>\n",
       "      <td>6.751692</td>\n",
       "      <td>0.004443</td>\n",
       "      <td>7.457003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paper</td>\n",
       "      <td>151.411983</td>\n",
       "      <td>197.678054</td>\n",
       "      <td>125.131573</td>\n",
       "      <td>318.460204</td>\n",
       "      <td>6.856129</td>\n",
       "      <td>7.162595</td>\n",
       "      <td>6.083913</td>\n",
       "      <td>9.886068</td>\n",
       "      <td>0.379972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986802</td>\n",
       "      <td>0.966409</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>8.157475</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>8.186649</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>8.041390</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>8.474081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paper</td>\n",
       "      <td>6.601659</td>\n",
       "      <td>12.791383</td>\n",
       "      <td>4.014503</td>\n",
       "      <td>6.934772</td>\n",
       "      <td>0.729829</td>\n",
       "      <td>0.989990</td>\n",
       "      <td>0.551607</td>\n",
       "      <td>0.771717</td>\n",
       "      <td>0.792864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996767</td>\n",
       "      <td>0.994398</td>\n",
       "      <td>0.008173</td>\n",
       "      <td>5.534304</td>\n",
       "      <td>0.006777</td>\n",
       "      <td>5.709364</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>5.391666</td>\n",
       "      <td>0.006911</td>\n",
       "      <td>5.650684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paper</td>\n",
       "      <td>42.516736</td>\n",
       "      <td>83.167102</td>\n",
       "      <td>43.673583</td>\n",
       "      <td>83.989244</td>\n",
       "      <td>2.422181</td>\n",
       "      <td>3.912203</td>\n",
       "      <td>2.600568</td>\n",
       "      <td>3.887831</td>\n",
       "      <td>0.646082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983117</td>\n",
       "      <td>0.967559</td>\n",
       "      <td>0.004873</td>\n",
       "      <td>6.488847</td>\n",
       "      <td>0.003663</td>\n",
       "      <td>6.868850</td>\n",
       "      <td>0.005105</td>\n",
       "      <td>6.503245</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>6.860561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>trash</td>\n",
       "      <td>2.930793</td>\n",
       "      <td>6.022017</td>\n",
       "      <td>2.954359</td>\n",
       "      <td>5.272097</td>\n",
       "      <td>0.401337</td>\n",
       "      <td>0.605044</td>\n",
       "      <td>0.451809</td>\n",
       "      <td>0.637454</td>\n",
       "      <td>0.867713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999444</td>\n",
       "      <td>0.999008</td>\n",
       "      <td>0.047057</td>\n",
       "      <td>4.855375</td>\n",
       "      <td>0.043049</td>\n",
       "      <td>5.045561</td>\n",
       "      <td>0.047221</td>\n",
       "      <td>4.901966</td>\n",
       "      <td>0.042851</td>\n",
       "      <td>5.091149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>trash</td>\n",
       "      <td>4.912921</td>\n",
       "      <td>12.474302</td>\n",
       "      <td>7.477684</td>\n",
       "      <td>11.149970</td>\n",
       "      <td>1.209368</td>\n",
       "      <td>1.761176</td>\n",
       "      <td>1.297569</td>\n",
       "      <td>1.747365</td>\n",
       "      <td>0.626781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998718</td>\n",
       "      <td>0.998087</td>\n",
       "      <td>0.030734</td>\n",
       "      <td>6.017515</td>\n",
       "      <td>0.028438</td>\n",
       "      <td>6.278786</td>\n",
       "      <td>0.030704</td>\n",
       "      <td>6.036419</td>\n",
       "      <td>0.028378</td>\n",
       "      <td>6.281896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>trash</td>\n",
       "      <td>3.547512</td>\n",
       "      <td>4.821310</td>\n",
       "      <td>2.653389</td>\n",
       "      <td>7.056465</td>\n",
       "      <td>0.670983</td>\n",
       "      <td>0.810907</td>\n",
       "      <td>0.625525</td>\n",
       "      <td>1.057405</td>\n",
       "      <td>0.792475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999242</td>\n",
       "      <td>0.997984</td>\n",
       "      <td>0.017830</td>\n",
       "      <td>5.318440</td>\n",
       "      <td>0.015449</td>\n",
       "      <td>5.468583</td>\n",
       "      <td>0.018440</td>\n",
       "      <td>5.287173</td>\n",
       "      <td>0.015239</td>\n",
       "      <td>5.595473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>trash</td>\n",
       "      <td>24.267444</td>\n",
       "      <td>50.958613</td>\n",
       "      <td>26.394684</td>\n",
       "      <td>45.554102</td>\n",
       "      <td>1.568682</td>\n",
       "      <td>2.320025</td>\n",
       "      <td>1.660891</td>\n",
       "      <td>2.305396</td>\n",
       "      <td>0.753475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993482</td>\n",
       "      <td>0.988751</td>\n",
       "      <td>0.010586</td>\n",
       "      <td>6.073735</td>\n",
       "      <td>0.008886</td>\n",
       "      <td>6.340741</td>\n",
       "      <td>0.010591</td>\n",
       "      <td>6.144308</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>6.388647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>trash</td>\n",
       "      <td>16.924250</td>\n",
       "      <td>28.435050</td>\n",
       "      <td>14.237664</td>\n",
       "      <td>31.828356</td>\n",
       "      <td>1.067107</td>\n",
       "      <td>1.487755</td>\n",
       "      <td>1.018343</td>\n",
       "      <td>1.609689</td>\n",
       "      <td>0.806914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995239</td>\n",
       "      <td>0.989365</td>\n",
       "      <td>0.013279</td>\n",
       "      <td>5.514527</td>\n",
       "      <td>0.010976</td>\n",
       "      <td>5.717461</td>\n",
       "      <td>0.013173</td>\n",
       "      <td>5.544028</td>\n",
       "      <td>0.010792</td>\n",
       "      <td>5.791164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      path  contrast_0  contrast_45  contrast_90  contrast_135  \\\n",
       "0    paper   34.627981    65.114734    31.449973     62.041637   \n",
       "1    paper   22.833313    24.654034     3.293407     26.701011   \n",
       "2    paper  151.411983   197.678054   125.131573    318.460204   \n",
       "3    paper    6.601659    12.791383     4.014503      6.934772   \n",
       "4    paper   42.516736    83.167102    43.673583     83.989244   \n",
       "..     ...         ...          ...          ...           ...   \n",
       "295  trash    2.930793     6.022017     2.954359      5.272097   \n",
       "296  trash    4.912921    12.474302     7.477684     11.149970   \n",
       "297  trash    3.547512     4.821310     2.653389      7.056465   \n",
       "298  trash   24.267444    50.958613    26.394684     45.554102   \n",
       "299  trash   16.924250    28.435050    14.237664     31.828356   \n",
       "\n",
       "     dissimilarity_0  dissimilarity_45  dissimilarity_90  dissimilarity_135  \\\n",
       "0           1.953303          2.805322          1.718842           2.611155   \n",
       "1           2.510284          2.726927          1.191559           2.855370   \n",
       "2           6.856129          7.162595          6.083913           9.886068   \n",
       "3           0.729829          0.989990          0.551607           0.771717   \n",
       "4           2.422181          3.912203          2.600568           3.887831   \n",
       "..               ...               ...               ...                ...   \n",
       "295         0.401337          0.605044          0.451809           0.637454   \n",
       "296         1.209368          1.761176          1.297569           1.747365   \n",
       "297         0.670983          0.810907          0.625525           1.057405   \n",
       "298         1.568682          2.320025          1.660891           2.305396   \n",
       "299         1.067107          1.487755          1.018343           1.609689   \n",
       "\n",
       "     homogeneity_0  ...  correlation_90  correlation_135     asm_0    asm_45  \\\n",
       "0         0.713239  ...        0.993843         0.987868  0.010774  6.293078   \n",
       "1         0.449226  ...        0.999565         0.996460  0.004571  7.319258   \n",
       "2         0.379972  ...        0.986802         0.966409  0.001399  8.157475   \n",
       "3         0.792864  ...        0.996767         0.994398  0.008173  5.534304   \n",
       "4         0.646082  ...        0.983117         0.967559  0.004873  6.488847   \n",
       "..             ...  ...             ...              ...       ...       ...   \n",
       "295       0.867713  ...        0.999444         0.999008  0.047057  4.855375   \n",
       "296       0.626781  ...        0.998718         0.998087  0.030734  6.017515   \n",
       "297       0.792475  ...        0.999242         0.997984  0.017830  5.318440   \n",
       "298       0.753475  ...        0.993482         0.988751  0.010586  6.073735   \n",
       "299       0.806914  ...        0.995239         0.989365  0.013279  5.514527   \n",
       "\n",
       "       asm_90   asm_135  entropy_0  entropy_45  entropy_90  entropy_135  \n",
       "0    0.009106  6.579898   0.010514    6.261537    0.009089     6.544980  \n",
       "1    0.004467  7.409926   0.005112    6.751692    0.004443     7.457003  \n",
       "2    0.001278  8.186649   0.001515    8.041390    0.001091     8.474081  \n",
       "3    0.006777  5.709364   0.008912    5.391666    0.006911     5.650684  \n",
       "4    0.003663  6.868850   0.005105    6.503245    0.003659     6.860561  \n",
       "..        ...       ...        ...         ...         ...          ...  \n",
       "295  0.043049  5.045561   0.047221    4.901966    0.042851     5.091149  \n",
       "296  0.028438  6.278786   0.030704    6.036419    0.028378     6.281896  \n",
       "297  0.015449  5.468583   0.018440    5.287173    0.015239     5.595473  \n",
       "298  0.008886  6.340741   0.010591    6.144308    0.008789     6.388647  \n",
       "299  0.010976  5.717461   0.013173    5.544028    0.010792     5.791164  \n",
       "\n",
       "[300 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasil = ekstraksiFitur(ekstraksiData, path)\n",
    "df = pd.DataFrame(hasil, columns=headers)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('sebelum_preprocessing_100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "df = pd.read_csv('sebelum_preprocessing_100.csv')\n",
    "\n",
    "X = df.drop('path', axis=1)\n",
    "y = df['path']\n",
    "\n",
    "pca = PCA(n_components=25)\n",
    "x = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors (KNN) Accuracy: 0.7\n",
      "Support Vector Machine (SVM) Accuracy: 0.8\n",
      "Random Forest Accuracy: 0.8166666666666667\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
    "print(\"K-Nearest Neighbors (KNN) Accuracy:\", knn_accuracy)\n",
    "\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "print(\"Support Vector Machine (SVM) Accuracy:\", svm_accuracy)\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Accuracy  Precision    Recall  F1-Score\n",
      "KNN            0.700000   0.734083  0.700000  0.701088\n",
      "SVM            0.800000   0.800000  0.800000  0.800000\n",
      "Random Forest  0.816667   0.838360  0.816667  0.820445\n"
     ]
    }
   ],
   "source": [
    "models = {'KNN': knn_pred, 'SVM': svm_pred, 'Random Forest': rf_pred}\n",
    "results = {}\n",
    "\n",
    "for model_name, y_pred in models.items():\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    results[model_name] = [accuracy, precision, recall, f1]\n",
    "\n",
    "results_df = pd.DataFrame(results, index=['Accuracy', 'Precision', 'Recall', 'F1-Score']).T\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melatih model KNN, SVM, dan Random Forest dengan data pelatihan (xTrain, yTrain). Memprediksi label untuk data pengujian (xTest) dengan masing-masing model dan menghitung metrik evaluasi: akurasi, presisi, recall, dan F1-Score. Metrik ini kemudian disimpan dalam DataFrame hasil dan dicetak untuk membandingkan performa masing-masing model. Pada akhirnya, didapatkan akurasi seperi pada gambar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
